{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Import and Loading",
   "id": "11d110839221d8db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import kagglehub # Import dataset from KaggleHub\n",
    "\n",
    "path = kagglehub.dataset_download(\"lainguyn123/student-performance-factors\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd # read the csv and store it in a dataframe\n",
    "import os\n",
    "\n",
    "print(os.listdir(path))\n",
    "df = pd.read_csv(os.path.join(path, \"StudentPerformanceFactors.csv\"), sep=',')"
   ],
   "id": "1e8c6d9ca51f6747",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Cleaning and Preprocessing",
   "id": "9438ca1f8be9456b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head()",
   "id": "5899fcd3e9c2f4b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "score_features = ['Attendance', 'Previous_Scores', 'Hours_Studied', 'Exam_Score']",
   "id": "940f30df0da1a73f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "score_df = df[score_features]",
   "id": "b6bb6240206fd194",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns # plotted a heatmap to visualize the correlation between the features\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "numeric_df = score_df.select_dtypes(include=['number'])\n",
    "sns.heatmap(numeric_df.corr(), annot=True)\n",
    "plt.show()"
   ],
   "id": "aa544e3e07b629dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features = [col for col in score_df.columns if col != 'Exam_Score']\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, feature in enumerate(features, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    plt.scatter(score_df[feature], score_df['Exam_Score'], alpha=0.6)\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Exam_Score')\n",
    "    plt.title(f'{feature} vs Exam_Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "819f060d392a8428",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Training",
   "id": "454a2ce99c6213ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split # split the data into training and testings sets\n",
    "\n",
    "score_df.dropna(inplace=True, axis=0)\n",
    "X = score_df.drop(columns=['Exam_Score', 'Previous_Scores', 'Attendance'])\n",
    "Y = score_df['Exam_Score']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state=42)\n"
   ],
   "id": "1da464d7956d1859",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X.describe()",
   "id": "ef89c9e032f0e7ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LinearRegression  # create linear regression model and fit\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,Y_train)"
   ],
   "id": "7381cdd46663d9d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "predictions = model.predict(X_test)",
   "id": "8e214863d4e9b90c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_test.head()",
   "id": "2565c3763ef01d76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Evaluation",
   "id": "6d6b88972140945c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "print(\"Predictions for the first 5 students:\")\n",
    "print(predictions[:5])\n",
    "print(\"Actual scores for the first 5 students:\")\n",
    "print(Y_test.head().values)\n",
    "\n",
    "print(\"Mean Squared Error:\", mean_squared_error(Y_test, predictions))\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(Y_test, predictions))\n",
    "print(\"R-squared:\", r2_score(Y_test, predictions))\n"
   ],
   "id": "c3692724526bd1da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Polynomial Regression",
   "id": "88cca2a5eadcad15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=3, include_bias=False) # transform the features into polynomial features\n",
    "X_poly_train = poly_features.fit_transform(X_train)\n",
    "X_poly_test = poly_features.transform(X_test)\n",
    "\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_poly_train,Y_train)"
   ],
   "id": "c331c94d8584febb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "poly_predictions = poly_model.predict(X_poly_test)",
   "id": "c01eb6511c72761a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Comparing Linear and Polynomial Regression",
   "id": "15bd9608b244a19a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Predictions for the first 5 students:\")\n",
    "print(poly_predictions[:5])\n",
    "print(\"Actual scores for the first 5 students:\")\n",
    "print(Y_test.head().values)\n",
    "\n",
    "print(\"Mean Squared Error:\", mean_squared_error(Y_test, poly_predictions))\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(Y_test, poly_predictions))\n",
    "print(\"R-squared:\", r2_score(Y_test, poly_predictions))\n"
   ],
   "id": "6dbe829af0e5c66e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Linear Regression:\")\n",
    "print(\"MSE:\", mean_squared_error(Y_test, predictions))\n",
    "print(\"MAE:\", mean_absolute_error(Y_test, predictions))\n",
    "print(\"R-squared:\", r2_score(Y_test, predictions))\n",
    "\n",
    "print(\"\\nPolynomial Regression:\")\n",
    "print(\"MSE:\", mean_squared_error(Y_test, poly_predictions))\n",
    "print(\"MAE:\", mean_absolute_error(Y_test, poly_predictions))\n",
    "print(\"R-squared:\", r2_score(Y_test, poly_predictions))\n"
   ],
   "id": "89d95cf52289880e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "hours_test = X_test['Hours_Studied'].values\n",
    "actual_scores = Y_test.values\n",
    "predicted_scores = poly_predictions\n",
    "\n",
    "# sort data based on hours studied to ensure a smooth line in the plot\n",
    "sort_index = np.argsort(hours_test)\n",
    "hours_sorted = hours_test[sort_index]\n",
    "actual_sorted = actual_scores[sort_index]\n",
    "predicted_sorted = predicted_scores[sort_index]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(hours_sorted, actual_sorted, color='blue', label='Actual Scores')\n",
    "plt.plot(hours_sorted, predicted_sorted, color='red', label='Polynomial Prediction', linewidth=2)\n",
    "plt.xlabel('Hours Studied')\n",
    "plt.ylabel('Exam Score')\n",
    "plt.title('Polynomial Regression: Exam Score vs Hours Studied')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "343a30aa6cd7ef6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hours_test = X_test['Hours_Studied'].values\n",
    "actual_scores = Y_test.values\n",
    "predicted_scores = predictions\n",
    "\n",
    "sort_index = np.argsort(hours_test)\n",
    "hours_sorted = hours_test[sort_index]\n",
    "actual_sorted = actual_scores[sort_index]\n",
    "predicted_sorted = predicted_scores[sort_index]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(hours_sorted, actual_sorted, color='blue', label='Actual Scores')\n",
    "plt.plot(hours_sorted, predicted_sorted, color='green', label='Linear Prediction', linewidth=2)\n",
    "plt.xlabel('Hours Studied')\n",
    "plt.ylabel('Exam Score')\n",
    "plt.title('Linear Regression: Exam Score vs Hours Studied')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "2059be4885a6fc4c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
